{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating AUC\n",
    "> The AUC value assesses how well a model can order observations from low probability to be target to high probability to be target. In Python, the __roc_auc_score__ function can be used to calculate the AUC of the model. It takes the true values of the target and the predictions as arguments.\n",
    "\n",
    "> You will make predictions again, before calculating its __roc_auc_score__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The model logreg from the last chapter has been created and fitted for you, the dataframe X contains the predictor columns of the basetable. Make predictions for the objects in the basetable.\n",
    "- Select the second column of predictions, as it contains the predictions for the target.\n",
    "- The true values of the target are loaded in y. Use the roc_auc_score function to calculate the AUC of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = logreg.predict_proba(X)\n",
    "predictions_target = predictions[:,1]\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc = roc_auc_score(y, predictions_target)\n",
    "print(round(auc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using different sets of variables\n",
    ">Adding more variables and therefore more complexity to your logistic regression model does not automatically result in more accurate models. In this exercise you can verify whether adding 3 variables to a model leads to a more accurate model.\n",
    "\n",
    ">variables_1 and variables_2 are available in your environment: you can print them to the console to explore what they look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Fit the logreg model using variables_2 which contains 3 additional variables compared to variables_1.\n",
    "- Make predictions for this model.\n",
    "- Calculate the AUC of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create appropriate dataframes\n",
    "X_1 = basetable[variables_1]\n",
    "X_2 = basetable[variables_2]\n",
    "y = basetable[[\"target\"]]\n",
    "\n",
    "# Create the logistic regression model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# Make predictions using the first set of variables and assign the AUC to auc_1\n",
    "logreg.fit(X_1, y)\n",
    "predictions_1 = logreg.predict_proba(X_1)[:,1]\n",
    "auc_1 = roc_auc_score(y, predictions_1)\n",
    "\n",
    "# Make predictions using the second set of variables and assign the AUC to auc_2\n",
    "logreg.fit(X_2, y)\n",
    "predictions_2 = logreg.predict_proba(X_2)[:,1]\n",
    "auc_2 = roc_auc_score(y, predictions_2)\n",
    "\n",
    "# Print auc_1 and auc_2\n",
    "print(round(auc_1,2))\n",
    "print(round(auc_2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the next best variable\n",
    ">The forward stepwise variable selection method starts with an empty variable set and proceeds in steps, where in each step the next best variable is added. To implement this procedure, two handy functions have been implemented for you.\n",
    "\n",
    ">The auc function calculates for a given variable set variables the AUC of the model that uses this variable set as predictors. The next_best function calculates which variable should be added in the next step to the variable list.\n",
    "\n",
    ">In this exercise, you will experiment with these functions to better understand their purpose. You will calculate the AUC of a given variable set, calculate which variable should be added next, and verify that this indeed results in an optimal AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- The auc function has been implemented for you. Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\" and \"min_gift\" as predictors. You should pass these variables in a list as the first argument to the auc function.\n",
    "- The next_best function has been implemented for you. Calculate which variable should be added next, given that \"max_gift\", \"mean_gift\" and \"min_gift\" are currently in the model, and \"age\" and \"gender_F\" are the candidate next predictors. The first argument of the next_best function is a list with the current variables, while the second argument is a list with the candidate predictors.\n",
    "- Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"age\" as predictors.\n",
    "- Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"gender_F\" as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\" and \"min_gift\" as predictors\n",
    "auc_current = auc([\"max_gift\", \"mean_gift\", \"min_gift\"], [\"target\"], basetable)\n",
    "print(round(auc_current,4))\n",
    "\n",
    "# Calculate which variable among \"age\" and \"gender_F\" should be added to the variables \"max_gift\", \"mean_gift\" and \"min_gift\"\n",
    "next_variable = next_best([\"max_gift\", \"mean_gift\", \"min_gift\"], [\"age\", \"gender_F\"], [\"target\"], basetable)\n",
    "print(next_variable)\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"age\" as predictors\n",
    "auc_current_age = auc([\"max_gift\", \"mean_gift\", \"min_gift\", \"age\"], [\"target\"], basetable)\n",
    "print(round(auc_current_age,4))\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"gender_F\" as predictors\n",
    "auc_current_gender_F = auc([\"max_gift\", \"mean_gift\", \"min_gift\", \"gender_F\"], [\"target\"], basetable)\n",
    "print(round(auc_current_gender_F,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the order of variables\n",
    "`The forward stepwise variable selection procedure starts with an empty set of variables, and adds predictors one by one. In each step, the predictor that has the highest AUC in combination with the current variables is selected.`\n",
    "\n",
    "`In this exercise you will learn to implement the forward stepwise variable selection procedure. To this end, you can use the next_best function that has been implemented for you. It can be used as follows:`\n",
    "\n",
    ">next_best(current_variables,candidate_variables,target,basetable)\n",
    "\n",
    "`where current_variables is the list of variables that is already in the model and candidate_variables the list of variables that can be added next.\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Use the function next_best to calculate the next best variable and assign it to next_variable.\n",
    "- Update the current_variables list.\n",
    "- Update the candidate_variables list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the candidate variables\n",
    "candidate_variables = list(basetable.columns.values)\n",
    "candidate_variables.remove(\"target\")\n",
    "\n",
    "# Initialize the current variables\n",
    "current_variables = []\n",
    "\n",
    "# The forward stepwise variable selection procedure\n",
    "number_iterations = 5\n",
    "for i in range(0, number_iterations):\n",
    "    next_variable = next_best(current_variables, candidate_variables, [\"target\"], basetable)\n",
    "    current_variables = current_variables + [next_variable]\n",
    "    candidate_variables.remove(next_variable)\n",
    "    print(\"Variable added in step \" + str(i+1)  + \" is \" + next_variable + \".\")\n",
    "print(current_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated variables\n",
    ">The first 10 variables that are added to the model are the following:\n",
    "\n",
    "['max_gift', 'number_gift', 'time_since_last_gift', 'mean_gift', 'income_high', 'age', 'country_USA', 'gender_F', 'income_low', 'country_UK']\n",
    "> As you can see, min_gift is not added. Does this mean that it is a bad variable? You can test the performance of the variable by using it in a model as a single variable and calculating the AUC. How does the AUC of min_gift compare to the AUC of income_high? To this end, you can use the function auc():\n",
    "\n",
    "- auc(variables, target, basetable)\n",
    "\n",
    "It can happen that a good variable is not added because it is highly correlated with a variable that is already in the model. You can test this calculating the correlation between these variables:\n",
    "\n",
    ">import numpy\n",
    "numpy.corrcoef(basetable[\"variable_1\"],basetable[\"variable_2\"])[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Calculate the AUC of the model using the variable min_gift only.\n",
    "- Calculate the AUC of the model using the variable income_high only.\n",
    "- Calculate the correlation between the variable min_gift and mean_gift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate the AUC of the model using min_gift only\n",
    "auc_min_gift = auc(['min_gift'], [\"target\"], basetable)\n",
    "print(round(auc_min_gift,2))\n",
    "\n",
    "# Calculate the AUC of the model using income_high only\n",
    "auc_income_high = auc(['income_high'], [\"target\"], basetable)\n",
    "print(round(auc_income_high,2))\n",
    "\n",
    "# Calculate the correlation between min_gift and mean_gift\n",
    "correlation = np.corrcoef(basetable[\"min_gift\"], basetable[\"mean_gift\"])[0,1]\n",
    "print(round(correlation,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning\n",
    ">In order to properly evaluate a model, one can partition the data in a train and test set. The train set contains the data the model is built on, and the test data is used to evaluate the model. This division is done randomly, but when the target incidence is low, it could be necessary to stratify, that is, to make sure that the train and test data contain an equal percentage of targets.\n",
    "\n",
    ">In this exercise you will partition the data with stratification and verify that the train and test data have equal target incidence. The train_test_split method has already been imported, and the X and y dataframes are available in your workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Stratify these dataframes using the train_test_split method. Make sure that train and test set are the same size, and have equal target incidence.\n",
    "- Calculate the target incidence of the train set. This is the number of targets in the train set divided by the number of observations in the train set.\n",
    "- Calculate the target incidence of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partitioning module\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Create dataframes with variables and target\n",
    "X = basetable.drop('target', 1)\n",
    "y = basetable[\"target\"]\n",
    "\n",
    "# Carry out 50-50 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.50, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Check whether train and test have same percentage targets\n",
    "print(round(sum(train[\"target\"])/len(train), 2))\n",
    "print(round(sum(test[\"target\"])/len(test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex. 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model on test and train\n",
    "* The function auc_train_test calculates the AUC of model that is built on a train set and evaluated on a test set:\n",
    "\n",
    "- auc_train, auc_test = auc_train_test(variables, target, train, test)\n",
    "- with variables a list of the names of the variables that is used in the model.\n",
    "\n",
    ">In this exercise, you will apply this function, and check whether the train and test AUC are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- The basetable is loaded. Partition the basetable such that the train set contains 70% of the data, and make sure that train and test set have equal target incidence.\n",
    "- Calculate the train and test AUC of the model using \"age\" and \"gender_F\" as predictors using the auc_train_test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partitioning module\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Create dataframes with variables and target\n",
    "X = basetable.drop('target', 1)\n",
    "y = basetable[\"target\"]\n",
    "\n",
    "# Carry out 70-30 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    " # Apply the auc_train_test function\n",
    "auc_train, auc_test = auc_train_test([\"age\",\"gender_F\"], [\"target\"], train, test)\n",
    "print(round(auc_train,2))\n",
    "print(round(auc_test,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
